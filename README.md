# CMPINF_2100_Fall_2020

Repository for weekly in-lecture programming examples.

## Week 01
* working with scripts and Jupyter notebooks
* variable assignment, basic operators, data types
* lists
* for-loop intro

## Week 02
* lots of practice with lists
* generating random numbers
* for-loops and list comprehensions
* writing functions
* central limit theorem and the standard error on the mean

## Week 03
* Side effects and aliasing
* Debugging within Jupyter notebooks
* Class, attributes, and methods
* NumPy arrays - creation, attributes, methods, manipulation
* Calculating the standard error on the mean with NumPy

## Week 04
* Creating Pandas Series and DataFrames
* Attributes, methods, subsetting, selecting, merging 
* Introduce exploring a real data set with Pandas
* Visualize the variability of the sample average with boxplots

## Week 05
* Applying functions over Pandas Series and DataFrames
* GroupBy, aggregating, and summarize: SPLIT-APPLY-COMBINE
* Reshaping DataFrames: wide and long formats, pivoting, and pivot tables

## Week 06
* matplotlib basics
* Introduction to Seaborn
* Histograms and Counts
* Density plots
* 2D histograms and 2D density plots
* Using color and facets to "split" by groups
* Scatter plots
* Joint plots, pair plots, correlation plots

## Week 07
* Introduction to cluster analysis
* Introduction to preprocessing
* Apply KMeans clustering to the penguins dataset
* Visualize cluster analysis results with PCA

## Week 08
* Identifying optimal number of clusters
* Hierarchical clustering - compare different linkages
* Interpreting Dendrograms
* More practice with PCA

## Week 09
* Introduction to linear models
* Generating random data from a linear model
* Visualizing the least squares estimator
* Introduction to statsmodels

## Week 10
* Interpreting coefficient estimates and confidence intervals
* What is R-squared?
* Visualizing residuals
* Additive terms, interactions, and polynomials
* Visualizing partial regression plots with statsmodels
* Introduction to logistic regression with the Space Shuttle Challenger data set

## Week 11
* Fitting logistic regression models with statsmodels
* Interpreting logistic regression coefficients and statistical significance
* Working with categorical inputs via dummy variables
* Interpreting dummy variables as relative effects and group level averages
* Binary classification performance metrics: Accuracy, Confusion Matrix, ROC curve

## Week 12
* Introduction to regularization via logistic regression with scikit-learn
* Impact of regularization strength on coefficient behavior
* Impact of regularization strength on model performance
* Introduction to cross-validation - K-fold and Stratified K-fold
* Tuning ridge and lasso penalties with cross-validation
